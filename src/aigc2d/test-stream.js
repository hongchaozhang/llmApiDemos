// Stream test with AIGC2D GPT models
const AIGC2DClient = require('./aigc2d-client');
const config = require('./config');

async function testStream() {
  console.log('ğŸŒŠ æµ‹è¯•AIGC2Dæµå¼è¾“å‡ºåŠŸèƒ½...\n');
  
  const client = new AIGC2DClient();
  console.log('ğŸŒ ä½¿ç”¨æ¥å£åœ°å€:', client.getCurrentURL());
  
  const messages = [
    { role: 'system', content: 'ä½ æ˜¯ä¸€ä¸ªåˆ›æ„å†™ä½œåŠ©æ‰‹ï¼Œè¯·ç”¨ä¸­æ–‡å†™ä½œã€‚' },
    { role: 'user', content: 'è¯·å†™ä¸€ä¸ªå…³äºç¨‹åºå‘˜ä½¿ç”¨AIå·¥å…·æé«˜å·¥ä½œæ•ˆç‡çš„å°æ•…äº‹ï¼Œå¤§çº¦200å­—ã€‚' }
  ];

  try {
    console.log('ğŸ“ æ­£åœ¨ç”Ÿæˆå›å¤ï¼ˆæµå¼è¾“å‡ºï¼‰ï¼š\n');
    console.log('ğŸ“– æ•…äº‹å†…å®¹ï¼š');
    console.log('-'.repeat(40));
    
    let fullResponse = '';
    await client.streamChat(messages, (chunk) => {
      process.stdout.write(chunk);
      fullResponse += chunk;
    }, config.models.gpt35, {
      temperature: 0.8, // æ›´æœ‰åˆ›æ„çš„è¾“å‡º
      maxTokens: 400
    });
    
    console.log('\n' + '-'.repeat(40));
    console.log('\nâœ… æµå¼è¾“å‡ºå®Œæˆï¼');
    console.log(`ğŸ“ æ€»å…±ç”Ÿæˆäº† ${fullResponse.length} ä¸ªå­—ç¬¦`);
    console.log(`ğŸ“ ä½¿ç”¨æ¨¡å‹: ${config.models.gpt35}`);
    
  } catch (error) {
    console.error('âŒ æµå¼è¾“å‡ºæµ‹è¯•å¤±è´¥ï¼š', error.message);
  }
}

if (require.main === module) {
  testStream();
}

module.exports = testStream;
